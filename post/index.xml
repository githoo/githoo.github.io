<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on babifarm.com</title>
    <link>http://babifarm.com/post/</link>
    <description>Recent content in Posts on babifarm.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Dec 2018 10:06:46 -0700</lastBuildDate>
    <atom:link href="http://babifarm.com/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>TFServing model load test</title>
      <link>http://babifarm.com/post/2018/12/tensorflow_serving_model_loadtest/</link>
      <pubDate>Sun, 23 Dec 2018 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2018/12/tensorflow_serving_model_loadtest/</guid>
      <description>Tensorflow Serving model test Tensorflow model #Half Plus Two test tfserving-gpu #from :https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/docker.md mkdir -p /tmp/tfserving cd /tmp/tfserving git clone https://github.com/tensorflow/serving nvidia-docker run -p 18501:8501 \ -v /tmp/tfserving/serving/tensorflow_serving/servables/tensorflow/testdata/saved_model_half_plus_two_gpu:/models/half_plus_two \ -e MODEL_NAME=half_plus_two -t tensorflow/serving:latest-gpu &amp;amp; curl -d &#39;{&amp;quot;instances&amp;quot;: [1.0, 2.0, 5.0]}&#39; \ -X POST http://localhost:18501/v1/models/half_plus_two:predict curl -H &amp;quot;Content-Type:application/json&amp;quot; -X POST --data &#39;{&amp;quot;instances&amp;quot;: [1.0, 2.0, 5.0]}&#39; -X POST http://localhost:18501/v1/models/half_plus_two:predict gatling loadtest import io.gatling.core.Predef._ import io.gatling.core.scenario.Simulation import io.gatling.http.Predef._ import scala.concurrent.duration._ class x_tfsgpuN extends</description>
    </item>
    
    <item>
      <title>neo4j remote access config and deploy</title>
      <link>http://babifarm.com/post/2018/12/neo4j_remote_access_config_and_deploy/</link>
      <pubDate>Sun, 23 Dec 2018 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2018/12/neo4j_remote_access_config_and_deploy/</guid>
      <description>neo4j远端访问配置及部署 1、neo4j的安装及配置 下载：neo4j-community-3.4.10-unix.tar.gz wget https://neo4j.com/artifact.php?name=neo4j-community-3.4.10-unix.tar.gz neo4j配置neo4j.conf: cat /export/soft/neo4j-community-3.4.10/conf/neo4j.conf |grep &#39;\=&#39;|grep -v &#39;#&#39; dbms.directories.import=import dbms.security.auth_enabled=false dbms.connectors.default_listen_address=0.0.0.0 dbms.connector.bolt.enabled=true dbms.connector.bolt.tls_level=OPTIONAL dbms.connector.bolt.listen_address=:7687 dbms.connector.http.enabled=true dbms.connector.http.listen_address=:7474 dbms.connector.https.enabled=true dbms.connector.https.listen_address=:7473 dbms.tx_log.rotation.retention_policy=1 days dbms.jvm.additional=-XX:+UseG1GC dbms.jvm.additional=-XX:-OmitStackTraceInFastThrow dbms.jvm.additional=-XX:+AlwaysPreTouch dbms.jvm.additional=-XX:+UnlockExperimentalVMOptions dbms.jvm.additional=-XX:+TrustFinalNonStaticFields dbms.jvm.additional=-XX:+DisableExplicitGC dbms.jvm.additional=-Djdk.tls.ephemeralDHKeySize=2048 dbms.jvm.additional=-Djdk.tls.rejectClientInitiatedRenegotiation=true dbms.windows_service_name=neo4j dbms.jvm.additional=-Dunsupported.dbms.udc.source=tarball neo4启动： /export/soft/neo4j-community-3.4.10/bin/neo4j start 2、nginx的安装及配置 nginx安装 #nginx安装 wget &#39;http://nginx.org/download/nginx-1.9.2.tar.gz&#39; tar xzvf nginx-1.9.2.tar.gz cd nginx-1.9.2 ./configure --prefix=/export/soft/nginx --with-stream make make install /export/soft/nginx/sbin/nginx -c /export/soft/nginx/conf/domains/pg.test.com nginx配置 #nginx配置 pg.test.com: #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log</description>
    </item>
    
    <item>
      <title>TFServing models deploy</title>
      <link>http://babifarm.com/post/2018/12/tensorflow_Serving_models_deploy/</link>
      <pubDate>Sat, 15 Dec 2018 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2018/12/tensorflow_Serving_models_deploy/</guid>
      <description>Tensorflow Serving 多模型部署 1、单模型方式 多个单模型启动： #单模型 root_path=&#39;/export/mtfs/TF&#39; docker run -p 10004:8501 -p 10005:8500 -v $root_path/corepw_model:/models/corepw_model -e MODEL_NAME=corepw_model -t tensorflow/serving &amp;amp;&amp;gt; my_log &amp;amp; docker run -p 10006:8501 -p 10007:8500 -v $root_path/brand_model:/models/brand_model -e MODEL_NAME=brand_model -t tensorflow/serving &amp;amp;&amp;gt; my_log1 &amp;amp; 访问示例： #访问例子 curl -H &amp;quot;Content-Type:application/json&amp;quot; -X POST http://localhost:10004/v1/models/corepw_model:predict -d &#39; &amp;gt; { &amp;gt; &amp;quot;instances&amp;quot;: [{ &amp;gt; &amp;quot;input_sentence_lengths&amp;quot;: 37, &amp;gt; &amp;quot;input_sentences&amp;quot;: [86, 1535, 0, 0, 0, 0, 0, 0, 0, 73, 41, 4, 0,</description>
    </item>
    
    <item>
      <title>TFServing-gpu deploy</title>
      <link>http://babifarm.com/post/2018/09/TFServing-gpu&#43;deploy/</link>
      <pubDate>Sat, 22 Sep 2018 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2018/09/TFServing-gpu&#43;deploy/</guid>
      <description>TFServing gpu 服务环境搭建 TFServing_docker-ce_nvidia-docker_nvidia-dirver_cuda_cudnn安装过程： 1、docker-ce install from:https://stackoverflow.com/questions/42981114/install-docker-ce-17-03-on-rhel7/45033117#45033117 #yum remove docker docker-common container-selinux docker-selinux docker-engine yum install -y yum-utils wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -ivh epel-release-latest-7.noarch.rpm subscription-manager repos --enable=rhel-7-server-extras-rpms yum install -y http://mirror.centos.org/centos/7/extras/x86_64/Packages/container-selinux-2.55-1.el7.noarch.rpm yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum install -y docker-ce systemctl restart docker systemctl status docker.service 2、nvidia-docker install from:https://blog.csdn.net/itaacy/article/details/72628792 wget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.1/nvidia-docker-1.0.1-1.x86_64.rpm rpm -i /tmp/nvidia-docker*.rpm &amp;amp;&amp;amp; rm /tmp/nvidia-docker*.rpm systemctl start nvidia-docker #check nvidia-docker run --rm nvidia/cuda nvidia-smi 3、cuda install #https://developer.nvidia.com/cuda-toolkit-archive wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run sh cuda_9.0.176_384.81_linux-run #安装过程中: #Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81？ (y)es/(n)o/(q)uit:n #注意：此步选择y，其余选y或者default即可 4、cudnn install #先从官方下载cudnn，解压后进行如下操作 cp cudnn/include/cudnn.h /usr/local/cuda-9.0/include cp cudnn/lib64/libcudnn* /usr/local/cuda-9.0/lib64 chmod a+r /usr/local/cuda-9.0/include/cudnn.h /usr/local/cuda-9.0/lib64/libcudnn* 5、TFServing deploy 启动TFServing: #模型路径 /root/predictproductword nvidia-docker run -p 10001:8501 -p 10000:8500 -v /root/predictproductword:/models/predictproductword -e MODEL_NAME=predictproductword -t tensorflow/serving:latest-gpu 启动日志： 08:53:40.758380: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: predictproductword version: 1} 08:53:40.806719: I tensorflow_serving/model_servers/main.cc:327] Running ModelServer at 0.0.0.0:8500 ...</description>
    </item>
    
    <item>
      <title>tensorflow-gpu install</title>
      <link>http://babifarm.com/post/2018/01/tensorflow-gpu-install/</link>
      <pubDate>Mon, 15 Jan 2018 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2018/01/tensorflow-gpu-install/</guid>
      <description>centos7下安装tensorflow-gup cuda8、cudnn8、tensorflow-gup安装过程： 1、下载相关软件 下载cuda8.0 wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda_8.0.61_375.26_linux-run 下载cudnn8.0-v6.0 wget http://developer2.download.nvidia.com/compute/machine-learning/cudnn/secure/v6/prod/8.0_20170427/cudnn-8.0-linux-x64-v6.0.tgz?yQ3tYwXxUZLlPzHDcsdoKYsza8ARGpYxi6k1Knhuhr-ZOKb5z4schgCD8kJF8LKCbYKRFniqc3_5rMpPPsZlGz1EBe_5GKe3KevXpgG6-Q0akSJByfXqqB0lH1wsl1c1rBJ4eZzVgX9GuGZpt5oXDMEjnwJoPGFLE7OaWBgMSpABsTdq8iuhumtn9ZV6pRByDN7JKbZD 2、安装cuda8.0 sh cuda_8.0.61_375.26_linux-run Do you accept the previously read EULA? accept/decline/quit: accept Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 387.26? (y)es/(n)o/(q)uit: y Install the CUDA 8.0 Toolkit? (y)es/(n)o/(q)uit: y Enter Toolkit Location Do you want to install a symbolic link at /usr/local/cuda? (y)es/(n)o/(q)uit: y Install the CUDA 8.0 Samples? (y)es/(n)o/(q)uit: y Enter CUDA Samples Location Installing the CUDA Toolkit in /usr/local/cuda-8.0 ...</description>
    </item>
    
    <item>
      <title>core dump</title>
      <link>http://babifarm.com/post/2017/09/core-dump/</link>
      <pubDate>Fri, 22 Sep 2017 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2017/09/core-dump/</guid>
      <description>core dump 定位分析 core dump 日志分析 core.212160 ###1、定位core发生的位置： gdb /export/servers/model/crf/so_lib/libCRFPP.so core.212160 (gdb) bt #6 &amp;lt;signal handler called&amp;gt; #7 0x00007f269c2a34be in CRFPP::TaggerImpl::forwardbackward() () from /tmp/crfpp-java-0.57-fcac54dc-13d1-48a4-b76d-b2941f15da0d-libCRFPP.so #8 0x00007f269c2aad92 in CRFPP::TaggerImpl::parse() () from /tmp/crfpp-java-0.57-fcac54dc-13d1-48a4-b76d-b2941f15da0d-libCRFPP.so #9 0x00007f269c2a18f0 in Java_org_chasen_crfpp_CRFPPJNI_Tagger_1parse_1_1SWIG_10 () from /tmp/crfpp-java-0.57-fcac54dc-13d1-48a4-b76d-b2941f15da0d-libCRFPP.so ###2、定位dump的细节 objdump -Cd /export/servers/model/crf/so_lib/libCRFPP.so &amp;gt; tt.txt cat tt.txt|grep &amp;quot;forwardbackward&amp;quot; [root@ckespam-e31e7701-2927318961-21969 App]# cat tt.txt|grep &amp;quot;forwardbackward&amp;quot; 0000000000010848 &amp;lt;CRFPP::TaggerImpl::forwardbackward()@plt&amp;gt;: 0000000000027f40 &amp;lt;CRFPP::TaggerImpl::forwardbackward()&amp;gt;: 27f5a: 0f 84 98 01 00 00 je 280f8 &amp;lt;CRFPP::TaggerImpl::forwardbackward()+0x1b8&amp;gt; 27f7a: 7e 65 jle</description>
    </item>
    
    <item>
      <title>gatling start</title>
      <link>http://babifarm.com/post/2017/09/gatling-start/</link>
      <pubDate>Sat, 09 Sep 2017 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2017/09/gatling-start/</guid>
      <description>gatlint start gatling quick start http://gatling.io/docs/current/quickstart/ 源码： https://github.com/gatling/gatling#wiki-loops gatling下载地址： https://repo1.maven.org/maven2/io/gatling/highcharts/gatling-charts-highcharts-bundle/2.2.5/gatling-charts-highcharts-bundle-2.2.5-bundle.zip gatling目录结构： bin目录下有2个脚本，gatling和recorder， gatling用来运行测试， recorder用来启动录制脚本的UI的（不推荐使用）， conf目录是关于Gatling自身的一些配置。 lib目录是Gatling自身依赖的库文件。 results目录用来存放测试报告的。 user-files目录是用来存放测试脚本的。 当运行gating脚本的时候，其会扫描user-files目录下的所有文件，列出其中所有的Simulation(一个测试类，里面可以包含任意多个测试场景) 执行压测： 执行gatling时，可通过参数制定具体执行那个实例，如下： ./bin/gatling.sh -s scala文件的class名字 比如./bin/gatling.sh -s TestGet 录制脚本： 需要配置Internet的代理才能录制成功。录制完成之后代码保存在user-files/simulations/ 目录下 配置浏览器代理：https://my.oschina.net/u/2419564/blog/613048 压测QPS和持续时间设置： QPS为1 持续60秒 setUp( recall.inject(constantUsersPerSec(1) during (60 seconds)) ).protocols(httpProtocol) QPS为10000持续一小时 setUp( recall.inject(constantUsersPerSec(10000) during (3600 seconds)) ).protocols(httpProtocol) ​ Gatling的报表： GLOBAL和DETAILS，其中GLOBAL主要是请求相关的统计数据，比如每秒请求数，请求成功与失败数等；其中DETAILS主要是请求时间相关的统计数据，比如请求响应时间，请求响应延迟时间等 官方指南： http://gatling.io/docs/current/ *User’s guide** What’s New Migration Guides Quickstart Advanced Tutorial General Session HTTP JMS Realtime monitoring Extensions Cookbook Information</description>
    </item>
    
    <item>
      <title>java profiler tool</title>
      <link>http://babifarm.com/post/2017/09/java-profiler/</link>
      <pubDate>Sat, 09 Sep 2017 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2017/09/java-profiler/</guid>
      <description>YourKit Java Profiler Yourkit是一款集Java profile数据收集及分析的工具，常用于分析Java程序性能瓶颈，带有cpu prifling、memory profiling等等各种profiling。以下会从yourkit使用场景、监控快照数据收集及分析、远程Java进程实时监控三方面来介绍。 收集Java profile快照数据 1、yourkit下载： window查看：https://www.yourkit.com/download/YourKit-JavaProfiler-2017.02-b66.exe Linux服务端插件：https://www.yourkit.com/download/YourKit-JavaProfiler-2017.02-b66.zip 2、应用程序执行脚本增加： -agentpath:/export/servers/java_profile/yjp-2017.02/bin/linux-x86-64/libyjpagent.so： eg: java -agentpath:/export/servers/java_profile/yjp-2017.02/bin/linux-x86-64/libyjpagent.so -jar /export/servers/proxy/proxy-1.0-SNAPSHOT.jar 3、收集数据： java -jar /export/servers/java_profile/yjp-2017.02/lib/yjp-controller-api-redist.jar localhost 10001 start-cpu-sampling java -jar /export/servers/java_profile/yjp-2017.02/lib/yjp-controller-api-redist.jar localhost 10001 stop-cpu-profiling java -jar /export/servers/java_profile/yjp-2017.02/lib/yjp-controller-api-redist.jar localhost 10001 capture-performance-snapshot 4、查看分析 打开yourkit，File&amp;ndash;&amp;gt;open snapshot，选中上一步down下的snapshot文件，如图可看出代码中哪些方法比较占CPU。还可看thread繁忙状态、内存使用、性能曲线中net io等。 远程调试 远程连接Java进程，实时查看其cpu、内存等监控（类似于visualVm，但比visualVm要详细）。Yourkit能做的事情并不止这些，其他类型的监控可参考官网介绍：https://www.yourkit.com/docs/java/help/。 yourkit软件 welcome page点击connect to remote application，按照以下格式输入： 跳板机:跳板机port Java应用服务器:监控收集端口，点击connect 远程调试 10.188.188.120:80 10.10.130.116:10001 应用服务器端执行： /export/servers/java_profile/yjp-2017.02/bin/yjp.sh -attach 参考：https://www.yourkit.com/docs/java/help/attach_wizard.jsp yourKit command YourKit Java Profiler2016.02-b36 command line tools Usage: java -jar</description>
    </item>
    
    <item>
      <title> Java内存模型设计思想 </title>
      <link>http://babifarm.com/post/2016/08/java-mem-design/</link>
      <pubDate>Sun, 28 Aug 2016 15:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2016/08/java-mem-design/</guid>
      <description>Java内存模型设计 多线程之间的数据通信 ：共享变量和消息机制 concurent java内存模型使用的共享变量机制 ACTOR模型使用的是消息机制 主内存 进程级？ 工作内存 线程级 多线程并发，即多核cpu执行 voliatile 实时更新cpu高速缓存(工作内存，线程使用的本地内存) atomic 机制 cas 锁机制 voliatile atomic 变量，控制读写状态 主内存 与 工作内存之间的关系 工作内存的初始变量是从主内存copy过来 工作内存默认是批处理更新主内存共享变量 如果是voliatile 共享变量，工作内存更新，立即更新主内存共享变量 主内存存放共享变量 堆 多cpu 每个cpu有高速缓存 cpu执行指令后的结果 voliatile机制 store load 保证依赖关系的顺序 编译成字节码时优化处理 happen-before 原则 写在读前 atomic 机制 cas机制保证多线程安全 compare and set 更新前比较新旧值，如果不等就更新，否则循环尝试更新</description>
    </item>
    
    <item>
      <title> 定时器设计思想 </title>
      <link>http://babifarm.com/post/2016/08/timer/</link>
      <pubDate>Sun, 28 Aug 2016 13:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2016/08/timer/</guid>
      <description>设计思想 关键环节： 周期 cycle 刻度 index 任务 task 1、计时器 系统时间（纳秒级）自增，维持一个执行周期C和当前index值I (C ，I) 2、任务表 (I,(C,T)) 按任务初始化一个任务周期表（环形） 表中每个刻度I存放任务映射关系：周期C和定时任务T 3、刻度 任务执行的时间精度 4、定时机器类型模型 不同的精度有不停的模型 如小时精度，一天24个小时，类似手表，可以映射到12个小时，1~12小时，12个刻度 任务T1要每隔7天的3点执行，(7*24+3)/12 14个周期+3小时 ，这个任务在任务表的设置（C=14 ，I=3 ，T=T1）</description>
    </item>
    
    <item>
      <title>利用Python远程拉取文件</title>
      <link>http://babifarm.com/post/2016/08/remote-pull-file/</link>
      <pubDate>Sat, 13 Aug 2016 13:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2016/08/remote-pull-file/</guid>
      <description>利用Python自带的包可以建立简单的web服务器。 cd到准备做服务器根目录的路径下，输入命令：python -m Web服务器模块 [端口号，默认8000] $ python -m SimpleHTTPServer 8080 然后就可以在浏览器中输入: http://localhost:端口号/路径 来访问服务器资源。 例如： http://localhost:8080/index.htm（当然index.htm文件得自己创建） 实例： 源头：192.168.1.1 $ cd /home/admin/ $ tar czvf test_deploy.tar.gz test_deploy $ python -m SimpleHTTPServer 8088 目的：192.168.1.2 $ cd /home/admin/;\rm -rvf test_deploy.tar.gz;wget http://192.168.1.1:8088/test_deploy.tar.gz;ll test_deploy.tar.gz|wc -l;tar -xzvf test_deploy.tar.gz;cd test_deploy;sh exe.sh;tail -f /export/servers/openresty/nginx/logs/error.log</description>
    </item>
    
    <item>
      <title> flume 整合 kafka </title>
      <link>http://babifarm.com/post/2016/08/flume-send-kafka/</link>
      <pubDate>Wed, 03 Aug 2016 13:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2016/08/flume-send-kafka/</guid>
      <description>一.kafka 安装 1、下载http://kafka.apache.org/downloads.html 2、解压tar -zxvf kafka_2.10-0.8.1.1.tgz 3、启动服务 1.首先启动zookeeper服务 bin/zookeeper-server-start.sh config/zookeeper.properties 2.启动Kafka bin/kafka-server-start.sh config/server.properties &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp; 3.创建topic创建一个&amp;quot;test&amp;quot;的topic，一个分区一个副本 bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 4.查看主题 bin/kafka-topics.sh --list --zookeeper localhost:2181 5.查看主题详情 bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test 6.删除主题 bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test 二. flume 整合 kafka 1、安装flume: download ：http://flume.apache.org/download.html tar -xvf apache-flume-1.6.0-bin.tar.gz 修改conf/flume-env.sh配置文件,设置JAVA_HOME变量 2、启动flume: $ cd apache-flume-1.6.0-bin $ bin/flume-ng agent -n producer -c conf/ -f conf/test-kafka-sink.conf -DFlume.root.logger=INFO,console 3、启动kafka消费 $ ./kafka-console-consumer.sh --zookeeper localhost:2181-topic test 123 4、测试发送消息给flume source nc localhost 8285 123 ok 5、配置文件 test-kafka-sink.conf ``` #memory channel called ch1 on agent1 producer.channels.channel1.type = memory # Define an Avro source called avro-source1 on agent1 and tell it # to bind to 0.0.0.0:41414.</description>
    </item>
    
    <item>
      <title>flume load balance 验证</title>
      <link>http://babifarm.com/post/2016/08/flume-load-balance/</link>
      <pubDate>Tue, 02 Aug 2016 13:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2016/08/flume-load-balance/</guid>
      <description>1、验证说明 数据从客户端发送给服务端，服务端进行负载均衡，发给两个处理节点： |----------&amp;gt;node1----&amp;gt;show ---test --&amp;gt; client --&amp;gt;server--&amp;gt;| |----------&amp;gt;node2----&amp;gt;show 2、安装flume: download ：http://flume.apache.org/download.html tar -xvf apache-flume-1.6.0-bin.tar.gz 修改conf/flume-env.sh配置文件,设置JAVA_HOME变量 3、测试环境： 在一台服务器上进行测试 4、相关配置： 在路径conf/simple_load下新建如下文件 client.conf # Define a memory channel called c1 on a0 a0.channels.c1.type = memory a0.channels.c1.capacity = 1000 a0.channels.c1.transactionCapacity = 100 a0.sources.r1.channels = c1 a0.sources.r1.type = netcat a0.sources.r1.bind = localhost a0.sources.r1.port = 43210 #a0.sinks.k1.type = logger a0.sinks.k1.type = avro a0.sinks.k1.channel = c1 a0.sinks.k1.hostname = localhost a0.sinks.k1.port = 43211 a0.channels = c1 a0.sources =</description>
    </item>
    
    <item>
      <title>bloom filter 教程  </title>
      <link>http://babifarm.com/post/2016/08/bloom%20filter/</link>
      <pubDate>Tue, 02 Aug 2016 09:36:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2016/08/bloom%20filter/</guid>
      <description>Bloom Filter概念和原理介绍 Bloom Filter是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。 Bloom Filter的这种高效是有一定代价的： 在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。 因此，Bloom Filter不适合那些“零错误”的应用场合。 而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。 为了说明Bloom Filter存在的重要意义，举一个实例： 假设要你写一个网络蜘蛛（web crawler）。由于网络间的链接错综复杂，蜘蛛在网络间爬行很可能会形成“环”。为了避免形成“环”，就需要知道蜘蛛已经访问过那些URL。给一个URL，怎样知道蜘蛛是否已经访问过呢？稍微想想，就会有如下几种方案： 1. 将访问过的URL保存到数据库。 2. 用HashSet将访问过的URL保存起来。那只需接近O(1)的代价就可以查到一个URL是否被访问过了。 3. URL经过MD5或SHA-1等单向哈希后再保存到HashSet或数据库。 4. Bit-Map方法。建立一个BitSet，将每个URL经过一个哈希函数映射到某一位。 方法1~3都是将访问过的URL完整保存，方法4则只标记URL的一个映射位。 以上方法在数据量较小的情况下都能完美解决问题，但是当数据量变得非常庞大时问题就来了。 方法1的缺点：数据量变得非常庞大后关系型数据库查询的效率会变得很低。而且每来一个URL就启动一次数据库查询是不是太小题大做了？ 方法2的缺点：太消耗内存。随着URL的增多，占用的内存会越来越多。就算只有1亿个URL，每个URL只算50个字符，就需要5GB内存。 方法3：由于字符串经过MD5处理后的信息摘要长度只有128Bit，SHA-1处理后也只有160Bit，因此方法3比方法2节省了好几倍的内存。 方法4消耗内存是相对较少的，但缺点是单一哈希函数发生冲突的概率太高。若要降低冲突发生的概率到1%，就要将BitSet的长度设置为URL个数的100倍。 实质上上面的算法都忽略了一个重要的隐含条件：允许小概率的出错，不一定要100%准确！也就是说少量url实际上没有没网络蜘蛛访问，而将它们错判为已访问的代价是很小的——大不了少抓几个网页呗。 Bloom Filter的算法 下面引入本篇的主角——Bloom Filter。其实上面方法4的思想已经很接近Bloom Filter了。方法四的致命缺点是冲突概率高，为了降低冲突的概念，Bloom Filter使用了多个哈希函数，而不是一个。 Bloom Filter算法如下： 创建一个m位BitSet，先将所有位初始化为0，然后选择k个不同的哈希函数。第i个哈希函数对字符串str哈希的结果记为h（i，str），且h（i，str）的范围是0到m-1 。 (1) 加入字符串过程 下面是每个字符串处理的过程，首先是将字符串str“记录”到BitSet中的过程： 对于字符串str，分别计算h（1，str），h（2，str）…… h（k，str）。然后将BitSet的第h（1，str）、h（2，str）…… h（k，str）位设为1。 这样就将字符串str映射到BitSet中的k个二进制位了. (2) 检查字符串是否存在的过程 下面是检查字符串str是否被BitSet记录过的过程： 对于字符串str，分别计算h（1，str），h（2，str）…… h（k，str）。然后检查BitSet的第h（1，str）、h（2，str）…… h（k，str）位是否为1，若其中任何一位不为1则可以判定str一定没有被记录过。若全部位都是1，则“认为”字符串str存在。 若一个字符串对应的Bit不全为1，则可以肯定该字符串一定没有被Bloom Filter记录过。（这是显然的，因为字符串被记录过，其对应的二进制位肯定全部被设为1了） 但是若一个字符串对应的Bit全为1，实际上是不能100%的肯定该字符串被Bloom Filter记录过的。（因为有可能该字符串的所有位都刚好是被其他字符串所对应）这种将该字符串划分错的情况，称为false positive 。 (3) 删除字符串过程 字符串加入了就被不能删除了，因为删除会影响到其他字符串。实在需要删除字符串的可以使用Counting bloomfilter(CBF)，这是一种基本Bloom Filter的变体，CBF将基本Bloom Filter每一个Bit改为一个计数器，这样就可以实现删除字符串的功能了。 Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。 Bloom</description>
    </item>
    
    <item>
      <title>protobuf 教程</title>
      <link>http://babifarm.com/post/2016/08/protobuf/</link>
      <pubDate>Tue, 02 Aug 2016 09:16:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2016/08/protobuf/</guid>
      <description>protobuf 版本 2.5.0 ，因为Hadoop hbase 都是这个版本 为了兼容 ，请用是用这个版本 maven插件生成 protobuf 文件 package p13.search; message BookCid3Inst { required string cid3 = 1; //三级分类 required float weight = 2;// 权重 } message UserBookInstCid3s { required string uid = 1; //用户pin repeated BookCid3Inst cid3Inst = 2; //用户图书下感兴趣的三级分类 } pom 插件设置 ，配置说明看注释 &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;maven-antrun-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.7&amp;lt;/version&amp;gt; &amp;lt;executions&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;id&amp;gt;compile-protoc&amp;lt;/id&amp;gt; &amp;lt;phase&amp;gt;generate-sources&amp;lt;/phase&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;tasks&amp;gt; &amp;lt;mkdir dir=&amp;quot;target/generated-sources&amp;quot;/&amp;gt; &amp;lt;path id=&amp;quot;proto.path&amp;quot;&amp;gt; &amp;lt;!--proto文件定义的位置--&amp;gt; &amp;lt;fileset dir=&amp;quot;src/main/resources/proto&amp;quot;&amp;gt; &amp;lt;include name=&amp;quot;**/*.proto&amp;quot;/&amp;gt; &amp;lt;/fileset&amp;gt; &amp;lt;/path&amp;gt; &amp;lt;pathconvert</description>
    </item>
    
  </channel>
</rss>
