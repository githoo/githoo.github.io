<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Core on babifarm.com</title>
    <link>http://babifarm.com/tags/core/</link>
    <description>Recent content in Core on babifarm.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 15 Dec 2018 10:06:46 -0700</lastBuildDate>
    <atom:link href="http://babifarm.com/tags/core/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>TFServing models deploy</title>
      <link>http://babifarm.com/post/2018/12/tensorflow_Serving_models_deploy/</link>
      <pubDate>Sat, 15 Dec 2018 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2018/12/tensorflow_Serving_models_deploy/</guid>
      <description>Tensorflow Serving 多模型部署 1、单模型方式 多个单模型启动： #单模型 root_path=&#39;/export/mtfs/TF&#39; docker run -p 10004:8501 -p 10005:8500 -v $root_path/corepw_model:/models/corepw_model -e MODEL_NAME=corepw_model -t tensorflow/serving &amp;amp;&amp;gt; my_log &amp;amp; docker run -p 10006:8501 -p 10007:8500 -v $root_path/brand_model:/models/brand_model -e MODEL_NAME=brand_model -t tensorflow/serving &amp;amp;&amp;gt; my_log1 &amp;amp; 访问示例： #访问例子 curl -H &amp;quot;Content-Type:application/json&amp;quot; -X POST http://localhost:10004/v1/models/corepw_model:predict -d &#39; &amp;gt; { &amp;gt; &amp;quot;instances&amp;quot;: [{ &amp;gt; &amp;quot;input_sentence_lengths&amp;quot;: 37, &amp;gt; &amp;quot;input_sentences&amp;quot;: [86, 1535, 0, 0, 0, 0, 0, 0, 0, 73, 41, 4, 0,</description>
    </item>
    
    <item>
      <title>TFServing-gpu deploy</title>
      <link>http://babifarm.com/post/2018/09/TFServing-gpu&#43;deploy/</link>
      <pubDate>Sat, 22 Sep 2018 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2018/09/TFServing-gpu&#43;deploy/</guid>
      <description>TFServing gpu 服务环境搭建 TFServing_docker-ce_nvidia-docker_nvidia-dirver_cuda_cudnn安装过程： 1、docker-ce install from:https://stackoverflow.com/questions/42981114/install-docker-ce-17-03-on-rhel7/45033117#45033117 #yum remove docker docker-common container-selinux docker-selinux docker-engine yum install -y yum-utils wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -ivh epel-release-latest-7.noarch.rpm subscription-manager repos --enable=rhel-7-server-extras-rpms yum install -y http://mirror.centos.org/centos/7/extras/x86_64/Packages/container-selinux-2.55-1.el7.noarch.rpm yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum install -y docker-ce systemctl restart docker systemctl status docker.service 2、nvidia-docker install from:https://blog.csdn.net/itaacy/article/details/72628792 wget -P /tmp https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.1/nvidia-docker-1.0.1-1.x86_64.rpm rpm -i /tmp/nvidia-docker*.rpm &amp;amp;&amp;amp; rm /tmp/nvidia-docker*.rpm systemctl start nvidia-docker #check nvidia-docker run --rm nvidia/cuda nvidia-smi 3、cuda install #https://developer.nvidia.com/cuda-toolkit-archive wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run sh cuda_9.0.176_384.81_linux-run #安装过程中: #Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81？ (y)es/(n)o/(q)uit:n #注意：此步选择y，其余选y或者default即可 4、cudnn install #先从官方下载cudnn，解压后进行如下操作 cp cudnn/include/cudnn.h /usr/local/cuda-9.0/include cp cudnn/lib64/libcudnn* /usr/local/cuda-9.0/lib64 chmod a+r /usr/local/cuda-9.0/include/cudnn.h /usr/local/cuda-9.0/lib64/libcudnn* 5、TFServing deploy 启动TFServing: #模型路径 /root/predictproductword nvidia-docker run -p 10001:8501 -p 10000:8500 -v /root/predictproductword:/models/predictproductword -e MODEL_NAME=predictproductword -t tensorflow/serving:latest-gpu 启动日志： 08:53:40.758380: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: predictproductword version: 1} 08:53:40.806719: I tensorflow_serving/model_servers/main.cc:327] Running ModelServer at 0.0.0.0:8500 ...</description>
    </item>
    
    <item>
      <title>tensorflow-gpu install</title>
      <link>http://babifarm.com/post/2018/01/tensorflow-gpu-install/</link>
      <pubDate>Mon, 15 Jan 2018 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2018/01/tensorflow-gpu-install/</guid>
      <description>centos7下安装tensorflow-gup cuda8、cudnn8、tensorflow-gup安装过程： 1、下载相关软件 下载cuda8.0 wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda_8.0.61_375.26_linux-run 下载cudnn8.0-v6.0 wget http://developer2.download.nvidia.com/compute/machine-learning/cudnn/secure/v6/prod/8.0_20170427/cudnn-8.0-linux-x64-v6.0.tgz?yQ3tYwXxUZLlPzHDcsdoKYsza8ARGpYxi6k1Knhuhr-ZOKb5z4schgCD8kJF8LKCbYKRFniqc3_5rMpPPsZlGz1EBe_5GKe3KevXpgG6-Q0akSJByfXqqB0lH1wsl1c1rBJ4eZzVgX9GuGZpt5oXDMEjnwJoPGFLE7OaWBgMSpABsTdq8iuhumtn9ZV6pRByDN7JKbZD 2、安装cuda8.0 sh cuda_8.0.61_375.26_linux-run Do you accept the previously read EULA? accept/decline/quit: accept Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 387.26? (y)es/(n)o/(q)uit: y Install the CUDA 8.0 Toolkit? (y)es/(n)o/(q)uit: y Enter Toolkit Location Do you want to install a symbolic link at /usr/local/cuda? (y)es/(n)o/(q)uit: y Install the CUDA 8.0 Samples? (y)es/(n)o/(q)uit: y Enter CUDA Samples Location Installing the CUDA Toolkit in /usr/local/cuda-8.0 ...</description>
    </item>
    
    <item>
      <title>core dump</title>
      <link>http://babifarm.com/post/2017/09/core-dump/</link>
      <pubDate>Fri, 22 Sep 2017 10:06:46 -0700</pubDate>
      
      <guid>http://babifarm.com/post/2017/09/core-dump/</guid>
      <description>core dump 定位分析 core dump 日志分析 core.212160 ###1、定位core发生的位置： gdb /export/servers/model/crf/so_lib/libCRFPP.so core.212160 (gdb) bt #6 &amp;lt;signal handler called&amp;gt; #7 0x00007f269c2a34be in CRFPP::TaggerImpl::forwardbackward() () from /tmp/crfpp-java-0.57-fcac54dc-13d1-48a4-b76d-b2941f15da0d-libCRFPP.so #8 0x00007f269c2aad92 in CRFPP::TaggerImpl::parse() () from /tmp/crfpp-java-0.57-fcac54dc-13d1-48a4-b76d-b2941f15da0d-libCRFPP.so #9 0x00007f269c2a18f0 in Java_org_chasen_crfpp_CRFPPJNI_Tagger_1parse_1_1SWIG_10 () from /tmp/crfpp-java-0.57-fcac54dc-13d1-48a4-b76d-b2941f15da0d-libCRFPP.so ###2、定位dump的细节 objdump -Cd /export/servers/model/crf/so_lib/libCRFPP.so &amp;gt; tt.txt cat tt.txt|grep &amp;quot;forwardbackward&amp;quot; [root@ckespam-e31e7701-2927318961-21969 App]# cat tt.txt|grep &amp;quot;forwardbackward&amp;quot; 0000000000010848 &amp;lt;CRFPP::TaggerImpl::forwardbackward()@plt&amp;gt;: 0000000000027f40 &amp;lt;CRFPP::TaggerImpl::forwardbackward()&amp;gt;: 27f5a: 0f 84 98 01 00 00 je 280f8 &amp;lt;CRFPP::TaggerImpl::forwardbackward()+0x1b8&amp;gt; 27f7a: 7e 65 jle</description>
    </item>
    
  </channel>
</rss>
